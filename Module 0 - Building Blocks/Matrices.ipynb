{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e78c3f5-5dd2-4859-afe6-8a206123f79c",
   "metadata": {},
   "source": [
    "# <u>Training Exercices - Matrices<u>\n",
    "\n",
    "__<u>Jorge Pineño Pérez<u>__ / Module 0 - Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a6b69-499f-48b1-964c-07f834b48dd7",
   "metadata": {},
   "source": [
    "__<u>Training Exercise M.1<u>__\n",
    "\n",
    "__1.__\n",
    "\n",
    "Model: $ y = Xb + e $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a7f8b6-0045-48a8-8191-7cc4f2a97075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy to use arrays as matrices\n",
    "import numpy as np\n",
    "\n",
    "# create the matrices and variables of the exercise\n",
    "y = np.array([[15.1],\n",
    "            [7.9],\n",
    "            [4.5],\n",
    "            [12.8],\n",
    "            [10.5]])\n",
    "\n",
    "X = np.array([[1, 25.5, 1.23],\n",
    "            [1, 40.8, 1.89],\n",
    "            [1, 30.2, 1.55],\n",
    "            [1, 4.3, 1.18],\n",
    "            [1, 10.7, 1.68]])\n",
    "\n",
    "b1 = np.array([[23],\n",
    "              [0.1],\n",
    "              [-8]])\n",
    "\n",
    "b2 = np.array([[22],\n",
    "              [-0.2],\n",
    "              [-7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174cf000-5f87-4130-b98c-ff1f466399d8",
   "metadata": {},
   "source": [
    "__2.__\n",
    "\n",
    "To know which of the two candidates for $b$ reduces $e$, we need to resolve the following equation, first using the vector `b1`, and then using `b2`:\n",
    "\n",
    "$$e = y - XB$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d15dc4-8eb2-4e5c-8f59-b30262fe77ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.61],\n",
       "       [-4.06],\n",
       "       [-9.12],\n",
       "       [-1.19],\n",
       "       [-0.13]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = y - X@b1\n",
    "e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d415fe9-c7fd-4e7b-96c2-a27beb9db6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.81],\n",
       "       [ 7.29],\n",
       "       [-0.61],\n",
       "       [-0.08],\n",
       "       [ 2.4 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = y - X@b2\n",
    "e2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bca574-f366-426f-8891-0f572aa7975a",
   "metadata": {},
   "source": [
    "We can now measure the distance from 0 of every element inside `e1` and `e2`, and then compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e175b02-6f23-4af6-ac2a-818147b60fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(e1[i]) for i in range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff5f149-83ed-4afa-9ba4-92f6ece360d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.19])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(e2[i]) for i in range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83339eb3-5530-467e-bb54-e16f3122ef72",
   "metadata": {},
   "source": [
    "As we can see, the unexplained part of the model is minimised by using `b1`, as $\\sum_{i=1}^{5} |e1_i| < \\sum_{i=1}^{5} |e2_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c952f-9a63-4ac6-9eeb-d578fbdc627b",
   "metadata": {},
   "source": [
    "__3.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cef3d-5e41-4415-a92d-508b7bd097bf",
   "metadata": {},
   "source": [
    "We identify $A$ as a matrix of dimensions $p \\times q$\n",
    "\n",
    "We identify $u$ as a row vector of dimensions $1 \\times p$\n",
    "\n",
    "We identify $v$ as a vector of dimensions $q \\times 1$\n",
    "\n",
    "We need to compute the dimensions of $d = u · A · v$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd17bb-2386-45e2-9cab-e1e12f1664c3",
   "metadata": {},
   "source": [
    "Firstly, the dimensions of the row vector $uA$ resulting from $u · A$ will be $1 \\times q$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14a6b8-274a-4dc8-b137-ff6d819d3fa7",
   "metadata": {},
   "source": [
    "Secondly, the dimensions of the result of the row vector $uA$ with dimensions $1 \\times q$ multiplied by $v$ will be $1 \\times 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c76e8b-f155-4cf9-9d9b-70c12fe0b863",
   "metadata": {},
   "source": [
    "Finally, we can express our steps in sigma notation:\n",
    "\n",
    "$$u · A = [\\sum_{k=1}^pu_k · A_{k,1}, \\sum_{k=1}^pu_k · A_{k,2}, ..., \\sum_{k=1}^pu_k · A_{k,q}]$$\n",
    "$$u · A = \\sum_{k=1}^pu_k · A_{k,i}$$\n",
    "$$d = \\sum_{i=1}^q(u · A)_i · v_i$$\n",
    "$$d = \\sum_{i=1}^q\\sum_{k=1}^pu_k · A_{k,i} · v_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b5f0f-2fe6-4635-b80b-3e6546244714",
   "metadata": {},
   "source": [
    "__4.__\n",
    "\n",
    "We identify $A$ as a matrix of dimensions $p \\times p$\n",
    "\n",
    "We identify $I$ as the identity matrix of dimensions $p \\times p$\n",
    "\n",
    "To answer the question, $(A + I)^2 = (A + I)(A + I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb275908-c923-4fa3-97c6-77d3994f44e1",
   "metadata": {},
   "source": [
    "This can be expanded as $(A + I)^2 = A^2 + AI + IA + I^2$, and finally, as $(A + I)^2 = A^2 + 2A + I$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0306e3-57a4-4ddb-b373-27bfc5d58b74",
   "metadata": {},
   "source": [
    "This is so, because multiplying any matrix by the identity matrix, or vice versa, results in the original matrix (the one which is not the identity), and the identity matrix multiplied by itself is still the identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a94a5-a252-4c3d-93cb-95f9f70d4d1f",
   "metadata": {},
   "source": [
    "__<u>Training Exercise M.2<u>__\n",
    "\n",
    "__1.__\n",
    "\n",
    "Expression to simplify: $ (a + b)'(a + b) $, given that $a$ and $b$ are two $(p \\times 1)$ vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79819c-bc25-495b-b050-c84586d20d8b",
   "metadata": {},
   "source": [
    "$$ (a + b)'(a + b) = $$\n",
    "$$ = (a' + b')(a + b) = $$\n",
    "$$ = a'a + a'b + b'a + b'b = $$\n",
    "$$ because \\space b'a = a'b, \\space and \\space they \\space are \\space scalars, \\space = a'a + 2a'b + b'b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170d621-b6f0-49da-8b8c-a6ca16034781",
   "metadata": {},
   "source": [
    "__2.__\n",
    "\n",
    "For $a$, a $(p \\times 1)$ vector, we can show that $a'a = tr(aa')$ the following way:\n",
    "\n",
    "$$if \\space a = \\begin{pmatrix}\n",
    "a_{11}\\\\\n",
    "a_{21}\\\\\n",
    "...\\\\\n",
    "a_{p1}\n",
    "\\end{pmatrix} \\space;\\space then \\space a' = \\begin{pmatrix}\n",
    "a_{11} & a_{21} & ... & a_{p1}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "$$a'a = a_{11}^2 + a_{21}^2 + ... + a_{p1}^2 \\space ;$$\n",
    "$$aa' = \\begin{pmatrix}\n",
    "a_{11}^2 & a_{11}a_{21} & ... & a_{11}a_{1p} \\\\\n",
    "a_{21}a_{11} & a_{21}^2 & ... & a_{21}a_{1p} \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "a_{p1}a_{11} & a_{p1}a_{21} & ... & a_{p1}^2\n",
    "\\end{pmatrix} \\space ;$$\n",
    "$$tr(aa') = a_{11}^2 + a_{21}^2 + ... + a_{p1}^2 = \\sum_{i=1}^p a_{i}^2 = a'a$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331ef2a-6abe-4272-83bd-7ce3cec2c911",
   "metadata": {},
   "source": [
    "__3.__\n",
    "\n",
    "For $A$, a $(p \\times p)$ (square) matrix, and $c$, a scalar, we can show that $tr(cA) = c·tr(A)$ the following way:\n",
    "\n",
    "$$if \\space A = \\begin{pmatrix}\n",
    "a_{11} & a_{12} & ... & a_{1p}\\\\\n",
    "a_{21} & a_{22} & ... & a_{2p}\\\\\n",
    "... & ... & ... & ...\\\\\n",
    "a_{p1} & a_{p2} & ... & a_{pp}\n",
    "\\end{pmatrix} \\space ; \\space then \\space cA = \\begin{pmatrix}\n",
    "ca_{11} & ca_{12} & ... & ca_{1p}\\\\\n",
    "ca_{21} & ca_{22} & ... & ca_{2p}\\\\\n",
    "... & ... & ... & ...\\\\\n",
    "ca_{p1} & ca_{p2} & ... & ca_{pp}\n",
    "\\end{pmatrix}$$\n",
    "$$then, \\space tr(A) = a_{11} · a_{22} · \\space ... \\space · a_{pp}$$\n",
    "$$finally, \\space tr(cA) = ca_{11} · ca_{22} · \\space ... \\space · ca_{pp} = c · (a_{11} · a_{22} · \\space ... \\space · a_{pp}) \\space ;$$\n",
    "$$so, \\space tr(cA) = c \\sum_{i=1}^p a_{ii} = c·tr(A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd11ae-31b9-4569-b098-c0325e2594ea",
   "metadata": {},
   "source": [
    "__4.__\n",
    "\n",
    "For $A$, a $(p \\times p)$ (square) matrix, and $c \\neq 0$, a scalar, we can find $B = (cA)^{-1}$ the following way:\n",
    "\n",
    "$$B = (cA)^{-1} = c^{-1} \\space · \\space A^{-1} \\space ;$$\n",
    "$$so, \\space B = 1 / c \\space · \\space A^{-1} = A^{-1} / c \\space ;$$\n",
    "$$i.e. \\space B = \\begin{pmatrix}\n",
    "{a/c}_{11} & {a/c}_{12} & ... & {a/c}_{1p}\\\\\n",
    "{a/c}_{21} & {a/c}_{22} & ... & {a/c}_{2p}\\\\\n",
    "... & ... & ... & ...\\\\\n",
    "{a/c}_{p1} & {a/c}_{p2} & ... & {a/c}_{pp}\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001a9be-a98a-44ed-85cf-be4d1d3b7c87",
   "metadata": {},
   "source": [
    "__5.__\n",
    "\n",
    "For $A$, a $(2 \\times 2)$ matrix, and $B(f)$, we can find $A^{-1}$ the following way:\n",
    "\n",
    "1. We recognise that, for $B$ to give $A^{-1}$, it would have to check the following relation:\n",
    "$$B \\space · \\space A = A \\space · \\space B = I \\space ;$$\n",
    "$$then, \\space B \\space · \\space A = A \\space · \\space B = I \\space = \\begin{pmatrix}\n",
    "a & b\\\\\n",
    "c & d\n",
    "\\end{pmatrix} \\space · \\space \\begin{pmatrix}\n",
    "d & -b\\\\\n",
    "-c & a\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 1\n",
    "\\end{pmatrix} \\space ;$$\n",
    "$$so, \\space \\begin{pmatrix}\n",
    "ad-bc & -ab+ba\\\\\n",
    "cd-cd & -bc+ad\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "2. From here, we can see that $ad-bc = 0, \\space and \\space cd-cd = 0$, and, of course, $ad-bc = -bc+ad$\n",
    "3. Therefore, $f = ad-bc \\space , \\space s.t. \\space ad-bc / f = 1$\n",
    "\n",
    "Finally, the inverse will only exist if $ad \\neq bc$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e1a17-0c42-4522-a46d-697546d76589",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "__6.__\n",
    "\n",
    "First, $ι'ι = \\sum_{i=1}^p ι_{i}^2$, and because $ι$ is the unit vector, $ι'ι = \\sum_{i=1}^p 1 = p$\n",
    "\n",
    "Second, $(ιι')^2 = ι \\space · \\space ι \\space · \\space (ι'ι) \\space · \\space ι' = pιι'$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532bfef-c66c-4536-b848-375f512f1fac",
   "metadata": {},
   "source": [
    "__<u>Training Exercise M.3<u>__\n",
    "\n",
    "__1.__\n",
    "\n",
    "If $b$ is a $(p \\times 1)$ vector, and $f(b) = b'b$, the gradient vector and Hessian matrix are:\n",
    "\n",
    "$$f(b) = b'b = \\sum_{i=1}^pb_i^2\\space;\n",
    "\\space\\frac{\\partial f}{\\partial b_i}(b) = 2b_i\\space;\n",
    "\\space\\frac{\\partial f}{\\partial b}(b) = 2b$$\n",
    "$$\\frac{\\partial^2 f}{\\partial b_i \\partial b'_i}(b) = 2I_p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2737f91-5f7c-4400-b9bc-a27fd3a6286e",
   "metadata": {},
   "source": [
    "__2.__\n",
    "\n",
    "If $A$ is a $(q \\times q)$ diagonal matrix, and $x$ is a $(q \\times 1)$ vector, we can prove that $A$ will be  positive definite if all diagonal elements are positive, and negative definite if all diagonal elements are negative\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "a_{11} & 0 & ... & 0 \\\\\n",
    "0 & a_{22} & ... & 0 \\\\\n",
    "... & ... & ... & ... \\\\\n",
    "0 & 0 & ... & a_{qq}\n",
    "\\end{pmatrix}\\space;\n",
    "\\space x = \\begin{pmatrix}\n",
    "x_{11} \\\\\n",
    "x_{21} \\\\\n",
    "... \\\\\n",
    "x_{q1}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "We first calculate $x'Ax$:\n",
    "\n",
    "$$x'A = \\begin{pmatrix}\n",
    "x_{11}a_{11} & x_{21}a_{22} & ... & x_{q1}a_{qq}\n",
    "\\end{pmatrix}$$\n",
    "$$x'Ax = x_{11}a_{11}x_{11} + x_{21}a_{22}x_{21} + \\dots + x_{q1}a_{qq}x_{q1} = x_{11}^2a_{11} + x_{21}^2a_{22} + \\dots + x_{q1}^2a_{qq} = \\sum_{\\substack{i=1 \\\\ j=1}}^q x_{j1}^2a_{ji}$$\n",
    "\n",
    "From our result, we can see that if $x \\neq 0$, and $a_{ji} > 0$, the diagonal matrix will be positive definite. Alternatively, if $a_{ji} < 0$, the diagonal matrix will be negative definite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
